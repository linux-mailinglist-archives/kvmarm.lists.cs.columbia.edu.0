Return-Path: <kvmarm-bounces@lists.cs.columbia.edu>
X-Original-To: lists+kvmarm@lfdr.de
Delivered-To: lists+kvmarm@lfdr.de
Received: from mm01.cs.columbia.edu (mm01.cs.columbia.edu [128.59.11.253])
	by mail.lfdr.de (Postfix) with ESMTP id 3E28B4147BB
	for <lists+kvmarm@lfdr.de>; Wed, 22 Sep 2021 13:22:56 +0200 (CEST)
Received: from localhost (localhost [127.0.0.1])
	by mm01.cs.columbia.edu (Postfix) with ESMTP id C0E7F4B0B8;
	Wed, 22 Sep 2021 07:22:55 -0400 (EDT)
X-Virus-Scanned: at lists.cs.columbia.edu
X-Spam-Flag: NO
X-Spam-Score: -4.201
X-Spam-Level: 
X-Spam-Status: No, score=-4.201 required=6.1 tests=[BAYES_00=-1.9,
	DNS_FROM_AHBL_RHSBL=2.699, RCVD_IN_DNSWL_HI=-5] autolearn=unavailable
Received: from mm01.cs.columbia.edu ([127.0.0.1])
	by localhost (mm01.cs.columbia.edu [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id 69VHVhdmwQ-z; Wed, 22 Sep 2021 07:22:55 -0400 (EDT)
Received: from mm01.cs.columbia.edu (localhost [127.0.0.1])
	by mm01.cs.columbia.edu (Postfix) with ESMTP id 4BCC84ACC9;
	Wed, 22 Sep 2021 07:22:54 -0400 (EDT)
Received: from localhost (localhost [127.0.0.1])
 by mm01.cs.columbia.edu (Postfix) with ESMTP id 70B994A49C
 for <kvmarm@lists.cs.columbia.edu>; Wed, 22 Sep 2021 07:22:52 -0400 (EDT)
X-Virus-Scanned: at lists.cs.columbia.edu
Received: from mm01.cs.columbia.edu ([127.0.0.1])
 by localhost (mm01.cs.columbia.edu [127.0.0.1]) (amavisd-new, port 10024)
 with ESMTP id cjKumPEMuddX for <kvmarm@lists.cs.columbia.edu>;
 Wed, 22 Sep 2021 07:22:51 -0400 (EDT)
Received: from mail.kernel.org (mail.kernel.org [198.145.29.99])
 by mm01.cs.columbia.edu (Postfix) with ESMTPS id 28BCC405A6
 for <kvmarm@lists.cs.columbia.edu>; Wed, 22 Sep 2021 07:22:51 -0400 (EDT)
Received: from disco-boy.misterjones.org (disco-boy.misterjones.org
 [51.254.78.96])
 (using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
 (No client certificate requested)
 by mail.kernel.org (Postfix) with ESMTPSA id 2D15660560;
 Wed, 22 Sep 2021 11:22:50 +0000 (UTC)
Received: from sofa.misterjones.org ([185.219.108.64] helo=why.misterjones.org)
 by disco-boy.misterjones.org with esmtpsa (TLS1.3) tls
 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (Exim 4.94.2)
 (envelope-from <maz@kernel.org>)
 id 1mT0Ku-00CJGO-5T; Wed, 22 Sep 2021 12:22:48 +0100
Date: Wed, 22 Sep 2021 12:22:47 +0100
Message-ID: <87czp0voqg.wl-maz@kernel.org>
From: Marc Zyngier <maz@kernel.org>
To: Jing Zhang <jingzhangos@google.com>
Subject: Re: [PATCH v1 3/3] KVM: arm64: Add histogram stats for handling time
 of arch specific exit reasons
In-Reply-To: <20210922010851.2312845-3-jingzhangos@google.com>
References: <20210922010851.2312845-1-jingzhangos@google.com>
 <20210922010851.2312845-3-jingzhangos@google.com>
User-Agent: Wanderlust/2.15.9 (Almost Unreal) SEMI-EPG/1.14.7 (Harue)
 FLIM-LB/1.14.9 (=?UTF-8?B?R29qxY0=?=) APEL-LB/10.8 EasyPG/1.0.0 Emacs/27.1
 (x86_64-pc-linux-gnu) MULE/6.0 (HANACHIRUSATO)
MIME-Version: 1.0 (generated by SEMI-EPG 1.14.7 - "Harue")
X-SA-Exim-Connect-IP: 185.219.108.64
X-SA-Exim-Rcpt-To: jingzhangos@google.com, kvm@vger.kernel.org,
 kvmarm@lists.cs.columbia.edu, pbonzini@redhat.com, will@kernel.org,
 dmatlack@google.com, pshier@google.com, oupton@google.com, seanjc@google.com
X-SA-Exim-Mail-From: maz@kernel.org
X-SA-Exim-Scanned: No (on disco-boy.misterjones.org);
 SAEximRunCond expanded to false
Cc: KVM <kvm@vger.kernel.org>, Sean Christopherson <seanjc@google.com>,
 Peter Shier <pshier@google.com>, David Matlack <dmatlack@google.com>,
 Paolo Bonzini <pbonzini@redhat.com>, Will Deacon <will@kernel.org>,
 KVMARM <kvmarm@lists.cs.columbia.edu>
X-BeenThere: kvmarm@lists.cs.columbia.edu
X-Mailman-Version: 2.1.14
Precedence: list
List-Id: Where KVM/ARM decisions are made <kvmarm.lists.cs.columbia.edu>
List-Unsubscribe: <https://lists.cs.columbia.edu/mailman/options/kvmarm>,
 <mailto:kvmarm-request@lists.cs.columbia.edu?subject=unsubscribe>
List-Archive: <https://lists.cs.columbia.edu/pipermail/kvmarm>
List-Post: <mailto:kvmarm@lists.cs.columbia.edu>
List-Help: <mailto:kvmarm-request@lists.cs.columbia.edu?subject=help>
List-Subscribe: <https://lists.cs.columbia.edu/mailman/listinfo/kvmarm>,
 <mailto:kvmarm-request@lists.cs.columbia.edu?subject=subscribe>
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: 7bit
Errors-To: kvmarm-bounces@lists.cs.columbia.edu
Sender: kvmarm-bounces@lists.cs.columbia.edu

Hi Jing,

On Wed, 22 Sep 2021 02:08:51 +0100,
Jing Zhang <jingzhangos@google.com> wrote:
> 
> These logarithmic histogram stats are useful for monitoring performance
> of handling for different kinds of VCPU exit reasons.
> 
> Signed-off-by: Jing Zhang <jingzhangos@google.com>
> ---
>  arch/arm64/include/asm/kvm_host.h | 36 ++++++++++++
>  arch/arm64/kvm/arm.c              |  4 ++
>  arch/arm64/kvm/guest.c            | 43 ++++++++++++++
>  arch/arm64/kvm/handle_exit.c      | 95 +++++++++++++++++++++++++++++++
>  4 files changed, 178 insertions(+)
> 
> diff --git a/arch/arm64/include/asm/kvm_host.h b/arch/arm64/include/asm/kvm_host.h
> index 4d65de22add3..f1a29ca3d4f3 100644
> --- a/arch/arm64/include/asm/kvm_host.h
> +++ b/arch/arm64/include/asm/kvm_host.h
> @@ -417,6 +417,9 @@ struct kvm_vcpu_arch {
>  
>  	/* Arch specific exit reason */
>  	enum arm_exit_reason exit_reason;
> +
> +	/* The timestamp for the last VCPU exit */
> +	u64 last_exit_time;
>  };
>  
>  /* Pointer to the vcpu's SVE FFR for sve_{save,load}_state() */
> @@ -605,6 +608,8 @@ struct kvm_vm_stat {
>  	struct kvm_vm_stat_generic generic;
>  };
>  
> +#define ARM_EXIT_HIST_CNT	64
> +
>  struct kvm_vcpu_stat {
>  	struct kvm_vcpu_stat_generic generic;
>  	u64 mmio_exit_user;
> @@ -641,6 +646,36 @@ struct kvm_vcpu_stat {
>  		u64 exit_fp_asimd;
>  		u64 exit_pac;
>  	};
> +	/* Histogram stats for handling time of arch specific exit reasons */
> +	struct {
> +		u64 exit_unknown_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_irq_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_el1_serror_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_hyp_gone_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_il_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_wfi_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_wfe_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_cp15_32_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_cp15_64_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_cp14_32_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_cp14_ls_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_cp14_64_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_hvc32_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_smc32_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_hvc64_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_smc64_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_sys64_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_sve_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_iabt_low_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_dabt_low_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_softstp_low_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_watchpt_low_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_breakpt_low_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_bkpt32_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_brk64_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_fp_asimd_hist[ARM_EXIT_HIST_CNT];
> +		u64 exit_pac_hist[ARM_EXIT_HIST_CNT];
> +	};

I'm sorry, but I don't think this is right, and I really wish you had
reached out before putting any effort in this.

This appears to be as ~13kB per vcpu worth of data that means
*nothing*. Counting exception syndrome occurrences doesn't say
anything about how important the associated exception is. A few
examples:

- exit_hyp_gone_hist: KVM is gone. We've removed the hypervisor. What
  is the point of this? How many values do you expect?

- exit_dabt_low_hist: page faults. Crucial data, isn't it? Permission,
  Access, or Translation fault? At which level? Caused by userspace or
  kernel? Resulted in a page being allocated or not? Read from swap?
  Successful or not?

- exit_pac_hist, exit_fp_asimd_hist: actually handled early, and only
  end-up in that part of the hypervisor when there is nothing to do
  (either there is no corresponding HW or the feature is disabled).

- exit_sys64_hist: System register traps. Which sysreg? With what effect?

Blindly exposing these numbers doesn't result in anything that can be
used for any sort of useful analysis and bloats the already huge data
structures. It also affects every single user, most of which do not
care about this data. It also doesn't scale. Are you going to keep
adding these counters and histograms every time the architecture (or
KVM itself) grows some new event?

Frankly, this is a job for BPF and the tracing subsystem, not for some
hardcoded syndrome accounting. It would allow to extract meaningful
information, prevent bloat, and crucially make it optional. Even empty
trace points like the ones used in the scheduler would be infinitely
better than this (load your own module that hooks into these trace
points, expose the data you want, any way you want).

As it stands, there is no way I'd be considering merging something
that looks like this series.

Thanks,

	M.

-- 
Without deviation from the norm, progress is not possible.
_______________________________________________
kvmarm mailing list
kvmarm@lists.cs.columbia.edu
https://lists.cs.columbia.edu/mailman/listinfo/kvmarm
