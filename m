Return-Path: <kvmarm-bounces@lists.cs.columbia.edu>
X-Original-To: lists+kvmarm@lfdr.de
Delivered-To: lists+kvmarm@lfdr.de
Received: from mm01.cs.columbia.edu (mm01.cs.columbia.edu [128.59.11.253])
	by mail.lfdr.de (Postfix) with ESMTP id 30ADD61E5D5
	for <lists+kvmarm@lfdr.de>; Sun,  6 Nov 2022 21:13:00 +0100 (CET)
Received: from localhost (localhost [127.0.0.1])
	by mm01.cs.columbia.edu (Postfix) with ESMTP id D6AE44B893;
	Sun,  6 Nov 2022 15:12:58 -0500 (EST)
X-Virus-Scanned: at lists.cs.columbia.edu
X-Spam-Flag: NO
X-Spam-Score: -1.788
X-Spam-Level: 
X-Spam-Status: No, score=-1.788 required=6.1 tests=[BAYES_00=-1.9,
	DKIM_SIGNED=0.1, RCVD_IN_DNSWL_BLOCKED=0.001, T_DKIM_INVALID=0.01,
	URIBL_BLOCKED=0.001] autolearn=unavailable
Authentication-Results: mm01.cs.columbia.edu (amavisd-new); dkim=softfail
	(fail, message has been altered) header.i=@kernel.org
Received: from mm01.cs.columbia.edu ([127.0.0.1])
	by localhost (mm01.cs.columbia.edu [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id 6IxfYosIaI-2; Sun,  6 Nov 2022 15:12:58 -0500 (EST)
Received: from mm01.cs.columbia.edu (localhost [127.0.0.1])
	by mm01.cs.columbia.edu (Postfix) with ESMTP id 7361C4B881;
	Sun,  6 Nov 2022 15:12:57 -0500 (EST)
Received: from localhost (localhost [127.0.0.1])
 by mm01.cs.columbia.edu (Postfix) with ESMTP id 06D794B881
 for <kvmarm@lists.cs.columbia.edu>; Sun,  6 Nov 2022 15:12:56 -0500 (EST)
X-Virus-Scanned: at lists.cs.columbia.edu
Received: from mm01.cs.columbia.edu ([127.0.0.1])
 by localhost (mm01.cs.columbia.edu [127.0.0.1]) (amavisd-new, port 10024)
 with ESMTP id DT4I31xXgGQ7 for <kvmarm@lists.cs.columbia.edu>;
 Sun,  6 Nov 2022 15:12:54 -0500 (EST)
Received: from ams.source.kernel.org (ams.source.kernel.org [145.40.68.75])
 by mm01.cs.columbia.edu (Postfix) with ESMTPS id 888D44B880
 for <kvmarm@lists.cs.columbia.edu>; Sun,  6 Nov 2022 15:12:54 -0500 (EST)
Received: from smtp.kernel.org (relay.kernel.org [52.25.139.140])
 (using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
 (No client certificate requested)
 by ams.source.kernel.org (Postfix) with ESMTPS id 3707DB80CB3;
 Sun,  6 Nov 2022 20:12:53 +0000 (UTC)
Received: by smtp.kernel.org (Postfix) with ESMTPSA id BB12DC433D6;
 Sun,  6 Nov 2022 20:12:51 +0000 (UTC)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple; d=kernel.org;
 s=k20201202; t=1667765571;
 bh=9lmG0INMTpzx6fMq26U4WqAKVrAanIfxqUn0n+FAzxg=;
 h=Date:From:To:Cc:Subject:In-Reply-To:References:From;
 b=l8BKSfhzT+kMLob1r988Iw1KXz7BPpLPTSIGLm+9UbNOcrdUDIbNhCaJMGq/0fJ92
 BWFXRIlVO40kTT1PXYXLNAbWWOqOjXgj0Lg5so3sLeY7xYPP6z19nu/ntBRrOQ1FBv
 XFK63m0wkdZxw5JUACsRJA8iVBSx2B2WMNEh2WxBk96mi3R1S6s3uBOXzTPiNKv9rS
 67AmjbPBqVkrtyAmw+ZulX0/Pg7veUWK5DLbvD5WVefYOfKMFVzQo7wr0+XGraTcIk
 E65T/LKlYDAfK737Ip/OxdoW//x+jhR1ByDgxMrAGerSx28cv1LlaDYeLLdtek6N15
 PJgC0CvYPPjaA==
Received: from sofa.misterjones.org ([185.219.108.64]
 helo=wait-a-minute.misterjones.org)
 by disco-boy.misterjones.org with esmtpsa (TLS1.3) tls
 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (Exim 4.95)
 (envelope-from <maz@kernel.org>) id 1orm0f-004FWH-5L;
 Sun, 06 Nov 2022 20:12:49 +0000
Date: Sun, 06 Nov 2022 20:12:22 +0000
Message-ID: <87iljrg7vd.wl-maz@kernel.org>
From: Marc Zyngier <maz@kernel.org>
To: Peter Xu <peterx@redhat.com>
Subject: Re: [PATCH v8 3/7] KVM: Support dirty ring in conjunction with bitmap
In-Reply-To: <Y2ffRYoqlQOxgVtk@x1n>
References: <20221104234049.25103-1-gshan@redhat.com>
 <20221104234049.25103-4-gshan@redhat.com>
 <87o7tkf5re.wl-maz@kernel.org> <Y2ffRYoqlQOxgVtk@x1n>
User-Agent: Wanderlust/2.15.9 (Almost Unreal) SEMI-EPG/1.14.7 (Harue)
 FLIM-LB/1.14.9 (=?UTF-8?B?R29qxY0=?=) APEL-LB/10.8 EasyPG/1.0.0 Emacs/27.1
 (x86_64-pc-linux-gnu) MULE/6.0 (HANACHIRUSATO)
MIME-Version: 1.0 (generated by SEMI-EPG 1.14.7 - "Harue")
X-SA-Exim-Connect-IP: 185.219.108.64
X-SA-Exim-Rcpt-To: peterx@redhat.com, gshan@redhat.com, kvmarm@lists.linux.dev,
 kvmarm@lists.cs.columbia.edu, kvm@vger.kernel.org, shuah@kernel.org,
 catalin.marinas@arm.com, andrew.jones@linux.dev, ajones@ventanamicro.com,
 bgardon@google.com, dmatlack@google.com, will@kernel.org,
 suzuki.poulose@arm.com, alexandru.elisei@arm.com, pbonzini@redhat.com,
 seanjc@google.com, oliver.upton@linux.dev, zhenyzha@redhat.com,
 shan.gavin@gmail.com
X-SA-Exim-Mail-From: maz@kernel.org
X-SA-Exim-Scanned: No (on disco-boy.misterjones.org);
 SAEximRunCond expanded to false
Cc: kvm@vger.kernel.org, catalin.marinas@arm.com, andrew.jones@linux.dev,
 dmatlack@google.com, will@kernel.org, shan.gavin@gmail.com, bgardon@google.com,
 kvmarm@lists.linux.dev, pbonzini@redhat.com, zhenyzha@redhat.com,
 shuah@kernel.org, kvmarm@lists.cs.columbia.edu, ajones@ventanamicro.com
X-BeenThere: kvmarm@lists.cs.columbia.edu
X-Mailman-Version: 2.1.14
Precedence: list
List-Id: Where KVM/ARM decisions are made <kvmarm.lists.cs.columbia.edu>
List-Unsubscribe: <https://lists.cs.columbia.edu/mailman/options/kvmarm>,
 <mailto:kvmarm-request@lists.cs.columbia.edu?subject=unsubscribe>
List-Archive: <https://lists.cs.columbia.edu/pipermail/kvmarm>
List-Post: <mailto:kvmarm@lists.cs.columbia.edu>
List-Help: <mailto:kvmarm-request@lists.cs.columbia.edu?subject=help>
List-Subscribe: <https://lists.cs.columbia.edu/mailman/listinfo/kvmarm>,
 <mailto:kvmarm-request@lists.cs.columbia.edu?subject=subscribe>
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: 7bit
Errors-To: kvmarm-bounces@lists.cs.columbia.edu
Sender: kvmarm-bounces@lists.cs.columbia.edu

Hi Peter,

On Sun, 06 Nov 2022 16:22:29 +0000,
Peter Xu <peterx@redhat.com> wrote:
> 
> Hi, Marc,
> 
> On Sun, Nov 06, 2022 at 03:43:17PM +0000, Marc Zyngier wrote:
> > > +Note that the bitmap here is only a backup of the ring structure, and
> > > +normally should only contain a very small amount of dirty pages, which
> > 
> > I don't think we can claim this. It is whatever amount of memory is
> > dirtied outside of a vcpu context, and we shouldn't make any claim
> > regarding the number of dirty pages.
> 
> The thing is the current with-bitmap design assumes that the two logs are
> collected in different windows of migration, while the dirty log is only
> collected after the VM is stopped.  So collecting dirty bitmap and sending
> the dirty pages within the bitmap will be part of the VM downtime.
> 
> It will stop to make sense if the dirty bitmap can contain a large portion
> of the guest memory, because then it'll be simpler to just stop the VM,
> transfer pages, and restart on dest node without any tracking mechanism.

Oh, I absolutely agree that the whole vcpu dirty ring makes zero sense
in general. It only makes sense if the source of the dirty pages is
limited to the vcpus, which is literally a corner case. Look at any
real machine, and you'll quickly realise that this isn't the case, and
that DMA *is* a huge source of dirty pages.

Here, we're just lucky enough not to have much DMA tracking yet. Once
that happens (and I have it from people doing the actual work that it
*is* happening), you'll realise that the dirty ring story is of very
limited use. So I'd rather drop anything quantitative here, as this is
likely to be wrong.

>
> [1]
> 
> > 
> > > +needs to be transferred during VM downtime. Collecting the dirty bitmap
> > > +should be the very last thing that the VMM does before transmitting state
> > > +to the target VM. VMM needs to ensure that the dirty state is final and
> > > +avoid missing dirty pages from another ioctl ordered after the bitmap
> > > +collection.
> > > +
> > > +To collect dirty bits in the backup bitmap, the userspace can use the
> > > +same KVM_GET_DIRTY_LOG ioctl. KVM_CLEAR_DIRTY_LOG shouldn't be needed
> > > +and its behavior is undefined since collecting the dirty bitmap always
> > > +happens in the last phase of VM's migration.
> > 
> > It isn't clear to me why KVM_CLEAR_DIRTY_LOG should be called out. If
> > you have multiple devices that dirty the memory, such as multiple
> > ITSs, why shouldn't userspace be allowed to snapshot the dirty state
> > multiple time? This doesn't seem like a reasonable restriction, and I
> > really dislike the idea of undefined behaviour here.
> 
> I suggested the paragraph because it's very natural to ask whether we'd
> need to CLEAR_LOG for this special GET_LOG phase, so I thought this could
> be helpful as a reference to answer that.
> 
> I wanted to make it clear that we don't need CLEAR_LOG at all in this case,
> as fundamentally clear log is about re-protect the guest pages, but if
> we're with the restriction of above (having the dirty bmap the last to
> collect and once and for all) then it'll make no sense to protect the guest
> page at all at this stage since src host shouldn't run after the GET_LOG
> then the CLEAR_LOG will be a vain effort.

That's not for you to decide, but userspace. I can perfectly expect
userspace saving an ITS, getting the bitmap, saving the pages and then
*clearing the log* before processing the next ITS. Or anything else.

And by the way, userspace is perfectly entitled to *restart* the VM on
the spot if it wants to. After all, there is absolutely nothing that
says "migration" here. You are reading it all over the place, but
that's not what the API is about.

Frankly, I don't see why we should put random limitation to this
API. We're not in the business of setting policies on what userspace
does.

> 
> I used "undefined" here just to be loose on the interface, also a hint that
> we should never do that for this specific GET_LOG.  If we want, we can
> ignore CLEAR_LOG in the future with ALLOW_BITMAP, and the undefined also
> provides the flexibility, but that's not really that important.
> 
> The wording could definitely be improved, or maybe even avoid mentioning
> the CLEAR_LOG might help, but IIUC the major thing to reach the consensus
> is not CLEAR_LOG itself but on whether we can have that assumption [1] and
> whether such a design of using dirty bmap is acceptable in general.

I don't know what [1] is, but the bitmap should behave correctly, no
matter what userspace does, and provide consistent results. We already
depend on this. If the current API cannot support this correctly, then
we should fix it before I take this series.

	M.

-- 
Without deviation from the norm, progress is not possible.
_______________________________________________
kvmarm mailing list
kvmarm@lists.cs.columbia.edu
https://lists.cs.columbia.edu/mailman/listinfo/kvmarm
