Return-Path: <kvmarm-bounces@lists.cs.columbia.edu>
X-Original-To: lists+kvmarm@lfdr.de
Delivered-To: lists+kvmarm@lfdr.de
Received: from mm01.cs.columbia.edu (mm01.cs.columbia.edu [128.59.11.253])
	by mail.lfdr.de (Postfix) with ESMTP id DB8744DAD8F
	for <lists+kvmarm@lfdr.de>; Wed, 16 Mar 2022 10:31:58 +0100 (CET)
Received: from localhost (localhost [127.0.0.1])
	by mm01.cs.columbia.edu (Postfix) with ESMTP id 3951C49EB5;
	Wed, 16 Mar 2022 05:31:58 -0400 (EDT)
X-Virus-Scanned: at lists.cs.columbia.edu
X-Spam-Flag: NO
X-Spam-Score: -1.789
X-Spam-Level: 
X-Spam-Status: No, score=-1.789 required=6.1 tests=[BAYES_00=-1.9,
	DKIM_SIGNED=0.1, T_DKIM_INVALID=0.01, URIBL_BLOCKED=0.001]
	autolearn=unavailable
Authentication-Results: mm01.cs.columbia.edu (amavisd-new); dkim=softfail
	(fail, message has been altered) header.i=@kernel.org
Received: from mm01.cs.columbia.edu ([127.0.0.1])
	by localhost (mm01.cs.columbia.edu [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id YQ6qW85C1hFC; Wed, 16 Mar 2022 05:31:58 -0400 (EDT)
Received: from mm01.cs.columbia.edu (localhost [127.0.0.1])
	by mm01.cs.columbia.edu (Postfix) with ESMTP id 5468E49EBC;
	Wed, 16 Mar 2022 05:31:56 -0400 (EDT)
Received: from localhost (localhost [127.0.0.1])
 by mm01.cs.columbia.edu (Postfix) with ESMTP id 8903340C10
 for <kvmarm@lists.cs.columbia.edu>; Wed, 16 Mar 2022 05:31:54 -0400 (EDT)
X-Virus-Scanned: at lists.cs.columbia.edu
Received: from mm01.cs.columbia.edu ([127.0.0.1])
 by localhost (mm01.cs.columbia.edu [127.0.0.1]) (amavisd-new, port 10024)
 with ESMTP id 3JzFC3Cm47qi for <kvmarm@lists.cs.columbia.edu>;
 Wed, 16 Mar 2022 05:31:53 -0400 (EDT)
Received: from dfw.source.kernel.org (dfw.source.kernel.org [139.178.84.217])
 by mm01.cs.columbia.edu (Postfix) with ESMTPS id 2041240B78
 for <kvmarm@lists.cs.columbia.edu>; Wed, 16 Mar 2022 05:31:53 -0400 (EDT)
Received: from smtp.kernel.org (relay.kernel.org [52.25.139.140])
 (using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
 (No client certificate requested)
 by dfw.source.kernel.org (Postfix) with ESMTPS id 33CE2615B9;
 Wed, 16 Mar 2022 09:31:52 +0000 (UTC)
Received: by smtp.kernel.org (Postfix) with ESMTPSA id 975DAC340E9;
 Wed, 16 Mar 2022 09:31:51 +0000 (UTC)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple; d=kernel.org;
 s=k20201202; t=1647423111;
 bh=fSCGQ6arI2RdJ4LoboTdKNwOpNI7I5ehCdLF0DCiPFQ=;
 h=Date:From:To:Cc:Subject:In-Reply-To:References:From;
 b=E2bHf7QGwyp/ofJzfmqlhfCyK/LwaCdR1FBWTbfiGh/MnoW6PX574YwZZz9YEN9kM
 ugZYQn3XTypMBjhXC5W1EJn08bsJTfYLXCsCBgONmPtBtEK4ZS/Or6volDiv9cFEgG
 Rsq8XFDHBX5mQWHOC+M0jMZblACja5GkeD0YcjoMGcNIqkXtg+H9oszBR3W+ZfyAdg
 QqG3aplmhq7mXQQR+A2wMNilxjf71zl42LJxRXt/ADoS5DXCXESUIB1ojVBvzQy/wT
 sR49H2CekwRBAk20RpUJqPaAeNullB+mfVg57m9Q3Ax4bjyItSoWX2s5/iyEUHmJE5
 myv++eiqrCcSg==
Received: from sofa.misterjones.org ([185.219.108.64] helo=why.misterjones.org)
 by disco-boy.misterjones.org with esmtpsa (TLS1.3) tls
 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (Exim 4.94.2)
 (envelope-from <maz@kernel.org>)
 id 1nUQ0T-00EsQq-7n; Wed, 16 Mar 2022 09:31:49 +0000
Date: Wed, 16 Mar 2022 09:31:48 +0000
Message-ID: <87bky6z1iz.wl-maz@kernel.org>
From: Marc Zyngier <maz@kernel.org>
To: Oliver Upton <oupton@google.com>
Subject: Re: [PATCH 2/4] KVM: arm64: vgic-v3: Implement MMIO-based LPI
 invalidation
In-Reply-To: <YjF07lltAEn6X22V@google.com>
References: <20220314164044.772709-1-maz@kernel.org>
 <20220314164044.772709-3-maz@kernel.org>
 <YjF07lltAEn6X22V@google.com>
User-Agent: Wanderlust/2.15.9 (Almost Unreal) SEMI-EPG/1.14.7 (Harue)
 FLIM-LB/1.14.9 (=?UTF-8?B?R29qxY0=?=) APEL-LB/10.8 EasyPG/1.0.0 Emacs/27.1
 (x86_64-pc-linux-gnu) MULE/6.0 (HANACHIRUSATO)
MIME-Version: 1.0 (generated by SEMI-EPG 1.14.7 - "Harue")
X-SA-Exim-Connect-IP: 185.219.108.64
X-SA-Exim-Rcpt-To: oupton@google.com, linux-arm-kernel@lists.infradead.org,
 kvm@vger.kernel.org, kvmarm@lists.cs.columbia.edu, kernel-team@android.com,
 andre.przywara@arm.com
X-SA-Exim-Mail-From: maz@kernel.org
X-SA-Exim-Scanned: No (on disco-boy.misterjones.org);
 SAEximRunCond expanded to false
Cc: Andre Przywara <andre.przywara@arm.com>, kernel-team@android.com,
 kvm@vger.kernel.org, linux-arm-kernel@lists.infradead.org,
 kvmarm@lists.cs.columbia.edu
X-BeenThere: kvmarm@lists.cs.columbia.edu
X-Mailman-Version: 2.1.14
Precedence: list
List-Id: Where KVM/ARM decisions are made <kvmarm.lists.cs.columbia.edu>
List-Unsubscribe: <https://lists.cs.columbia.edu/mailman/options/kvmarm>,
 <mailto:kvmarm-request@lists.cs.columbia.edu?subject=unsubscribe>
List-Archive: <https://lists.cs.columbia.edu/pipermail/kvmarm>
List-Post: <mailto:kvmarm@lists.cs.columbia.edu>
List-Help: <mailto:kvmarm-request@lists.cs.columbia.edu?subject=help>
List-Subscribe: <https://lists.cs.columbia.edu/mailman/listinfo/kvmarm>,
 <mailto:kvmarm-request@lists.cs.columbia.edu?subject=subscribe>
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: 7bit
Errors-To: kvmarm-bounces@lists.cs.columbia.edu
Sender: kvmarm-bounces@lists.cs.columbia.edu

On Wed, 16 Mar 2022 05:26:06 +0000,
Oliver Upton <oupton@google.com> wrote:
> 
> Hi Marc,
> 
> On Mon, Mar 14, 2022 at 04:40:42PM +0000, Marc Zyngier wrote:
> > Since GICv4.1, it has become legal for an implementation to advertise
> > GICR_{INVLPIR,INVALLR,SYNCR} while having an ITS, allowing for a more
> > efficient invalidation scheme (no guest command queue contention when
> > multiple CPUs are generating invalidations).
> > 
> > Provide the invalidation registers as a primitive to their ITS
> > counterpart. Note that we don't advertise them to the guest yet
> > (the architecture allows an implementation to do this).
> > 
> > Signed-off-by: Marc Zyngier <maz@kernel.org>
> > ---
> >  arch/arm64/kvm/vgic/vgic-its.c     | 62 ++++++++++++++++++++----------
> >  arch/arm64/kvm/vgic/vgic-mmio-v3.c | 62 ++++++++++++++++++++++++++++++
> >  arch/arm64/kvm/vgic/vgic.h         |  4 ++
> >  include/kvm/arm_vgic.h             |  1 +
> >  4 files changed, 108 insertions(+), 21 deletions(-)
> > 
> > diff --git a/arch/arm64/kvm/vgic/vgic-its.c b/arch/arm64/kvm/vgic/vgic-its.c
> > index 089fc2ffcb43..cc62d8a8180f 100644
> > --- a/arch/arm64/kvm/vgic/vgic-its.c
> > +++ b/arch/arm64/kvm/vgic/vgic-its.c
> > @@ -1272,6 +1272,11 @@ static int vgic_its_cmd_handle_clear(struct kvm *kvm, struct vgic_its *its,
> >  	return 0;
> >  }
> >  
> > +int vgic_its_inv_lpi(struct kvm *kvm, struct vgic_irq *irq)
> > +{
> > +	return update_lpi_config(kvm, irq, NULL, true);
> > +}
> > +
> >  /*
> >   * The INV command syncs the configuration bits from the memory table.
> >   * Must be called with the its_lock mutex held.
> > @@ -1288,7 +1293,41 @@ static int vgic_its_cmd_handle_inv(struct kvm *kvm, struct vgic_its *its,
> >  	if (!ite)
> >  		return E_ITS_INV_UNMAPPED_INTERRUPT;
> >  
> > -	return update_lpi_config(kvm, ite->irq, NULL, true);
> > +	return vgic_its_inv_lpi(kvm, ite->irq);
> > +}
> > +
> > +/**
> > + * vgic_its_invall - invalidate all LPIs targetting a given vcpu
> > + * @vcpu: the vcpu for which the RD is targetted by an invalidation
> > + *
> > + * Contrary to the INVALL command, this targets a RD instead of a
> > + * collection, and we don't need to hold the its_lock, since no ITS is
> > + * involved here.
> > + */
> > +int vgic_its_invall(struct kvm_vcpu *vcpu)
> > +{
> > +	struct kvm *kvm = vcpu->kvm;
> > +	int irq_count, i = 0;
> > +	u32 *intids;
> > +
> > +	irq_count = vgic_copy_lpi_list(kvm, vcpu, &intids);
> > +	if (irq_count < 0)
> > +		return irq_count;
> > +
> > +	for (i = 0; i < irq_count; i++) {
> > +		struct vgic_irq *irq = vgic_get_irq(kvm, NULL, intids[i]);
> > +		if (!irq)
> > +			continue;
> > +		update_lpi_config(kvm, irq, vcpu, false);
> > +		vgic_put_irq(kvm, irq);
> > +	}
> > +
> > +	kfree(intids);
> > +
> > +	if (vcpu->arch.vgic_cpu.vgic_v3.its_vpe.its_vm)
> > +		its_invall_vpe(&vcpu->arch.vgic_cpu.vgic_v3.its_vpe);
> > +
> > +	return 0;
> >  }
> 
> nit: the refactoring happening at the same time as the functional change
> is a bit distracting. Looks fine though.

Yeah, it didn't seem to warrant an extra patch, given that we're
really only moving things about.

> 
> >  /*
> > @@ -1305,32 +1344,13 @@ static int vgic_its_cmd_handle_invall(struct kvm *kvm, struct vgic_its *its,
> >  	u32 coll_id = its_cmd_get_collection(its_cmd);
> >  	struct its_collection *collection;
> >  	struct kvm_vcpu *vcpu;
> > -	struct vgic_irq *irq;
> > -	u32 *intids;
> > -	int irq_count, i;
> >  
> >  	collection = find_collection(its, coll_id);
> >  	if (!its_is_collection_mapped(collection))
> >  		return E_ITS_INVALL_UNMAPPED_COLLECTION;
> >  
> >  	vcpu = kvm_get_vcpu(kvm, collection->target_addr);
> > -
> > -	irq_count = vgic_copy_lpi_list(kvm, vcpu, &intids);
> > -	if (irq_count < 0)
> > -		return irq_count;
> > -
> > -	for (i = 0; i < irq_count; i++) {
> > -		irq = vgic_get_irq(kvm, NULL, intids[i]);
> > -		if (!irq)
> > -			continue;
> > -		update_lpi_config(kvm, irq, vcpu, false);
> > -		vgic_put_irq(kvm, irq);
> > -	}
> > -
> > -	kfree(intids);
> > -
> > -	if (vcpu->arch.vgic_cpu.vgic_v3.its_vpe.its_vm)
> > -		its_invall_vpe(&vcpu->arch.vgic_cpu.vgic_v3.its_vpe);
> > +	vgic_its_invall(vcpu);
> >  
> >  	return 0;
> >  }
> > diff --git a/arch/arm64/kvm/vgic/vgic-mmio-v3.c b/arch/arm64/kvm/vgic/vgic-mmio-v3.c
> > index 58e40b4874f8..186bf35078bf 100644
> > --- a/arch/arm64/kvm/vgic/vgic-mmio-v3.c
> > +++ b/arch/arm64/kvm/vgic/vgic-mmio-v3.c
> > @@ -525,6 +525,59 @@ static void vgic_mmio_write_pendbase(struct kvm_vcpu *vcpu,
> >  			   pendbaser) != old_pendbaser);
> >  }
> >  
> > +static unsigned long vgic_mmio_read_sync(struct kvm_vcpu *vcpu,
> > +					 gpa_t addr, unsigned int len)
> > +{
> > +	return !!atomic_read(&vcpu->arch.vgic_cpu.syncr_busy);
> > +}
> > +
> > +static void vgic_make_rdist_busy(struct kvm_vcpu *vcpu, bool busy)
> 
> nit: s/make/set, since you use this helper to decrement the counter too.

Sure, works for me.

> > +{
> > +	if (busy) {
> > +		atomic_inc(&vcpu->arch.vgic_cpu.syncr_busy);
> > +		smp_mb__after_atomic();
> > +	} else {
> > +		smp_mb__before_atomic();
> > +		atomic_dec(&vcpu->arch.vgic_cpu.syncr_busy);
> > +	}
> > +}
> > +
> > +static void vgic_mmio_write_invlpi(struct kvm_vcpu *vcpu,
> > +				   gpa_t addr, unsigned int len,
> > +				   unsigned long val)
> > +{
> > +	struct vgic_cpu *vgic_cpu = &vcpu->arch.vgic_cpu;
> > +	struct vgic_irq *irq;
> > +
> > +	if (!vgic_cpu->lpis_enabled)
> > +		return;
> > +
> > +	vgic_make_rdist_busy(vcpu, true);
> > +
> > +	irq = vgic_get_irq(vcpu->kvm, NULL, val);
> > +	if (!irq)
> > +		return;
> 
> Isn't the busy counter unbalanced if you return early?

Huh, well caught. Fix incoming.

Thanks,

	M.

-- 
Without deviation from the norm, progress is not possible.
_______________________________________________
kvmarm mailing list
kvmarm@lists.cs.columbia.edu
https://lists.cs.columbia.edu/mailman/listinfo/kvmarm
