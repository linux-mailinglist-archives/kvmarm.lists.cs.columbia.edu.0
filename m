Return-Path: <kvmarm-bounces@lists.cs.columbia.edu>
X-Original-To: lists+kvmarm@lfdr.de
Delivered-To: lists+kvmarm@lfdr.de
Received: from mm01.cs.columbia.edu (mm01.cs.columbia.edu [128.59.11.253])
	by mail.lfdr.de (Postfix) with ESMTP id F3B5A42172
	for <lists+kvmarm@lfdr.de>; Wed, 12 Jun 2019 11:53:12 +0200 (CEST)
Received: from localhost (localhost [127.0.0.1])
	by mm01.cs.columbia.edu (Postfix) with ESMTP id 87D144A51B;
	Wed, 12 Jun 2019 05:53:12 -0400 (EDT)
X-Virus-Scanned: at lists.cs.columbia.edu
X-Spam-Flag: NO
X-Spam-Score: 0.799
X-Spam-Level: 
X-Spam-Status: No, score=0.799 required=6.1 tests=[BAYES_00=-1.9,
	DNS_FROM_AHBL_RHSBL=2.699] autolearn=unavailable
Received: from mm01.cs.columbia.edu ([127.0.0.1])
	by localhost (mm01.cs.columbia.edu [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id fhOkN1ZtXEPO; Wed, 12 Jun 2019 05:53:12 -0400 (EDT)
Received: from mm01.cs.columbia.edu (localhost [127.0.0.1])
	by mm01.cs.columbia.edu (Postfix) with ESMTP id 10C574A519;
	Wed, 12 Jun 2019 05:53:11 -0400 (EDT)
Received: from localhost (localhost [127.0.0.1])
 by mm01.cs.columbia.edu (Postfix) with ESMTP id 4445A4A4EE
 for <kvmarm@lists.cs.columbia.edu>; Wed, 12 Jun 2019 05:53:10 -0400 (EDT)
X-Virus-Scanned: at lists.cs.columbia.edu
Received: from mm01.cs.columbia.edu ([127.0.0.1])
 by localhost (mm01.cs.columbia.edu [127.0.0.1]) (amavisd-new, port 10024)
 with ESMTP id 28Nef-4vEe7k for <kvmarm@lists.cs.columbia.edu>;
 Wed, 12 Jun 2019 05:52:36 -0400 (EDT)
Received: from foss.arm.com (foss.arm.com [217.140.110.172])
 by mm01.cs.columbia.edu (Postfix) with ESMTP id B8BE04A4E6
 for <kvmarm@lists.cs.columbia.edu>; Wed, 12 Jun 2019 05:52:36 -0400 (EDT)
Received: from usa-sjc-imap-foss1.foss.arm.com (unknown [10.121.207.14])
 by usa-sjc-mx-foss1.foss.arm.com (Postfix) with ESMTP id 3A76B28;
 Wed, 12 Jun 2019 02:52:36 -0700 (PDT)
Received: from big-swifty.misterjones.org (unknown [172.31.20.19])
 by usa-sjc-imap-foss1.foss.arm.com (Postfix) with ESMTPSA id CDC4C3F246;
 Wed, 12 Jun 2019 02:54:15 -0700 (PDT)
Date: Wed, 12 Jun 2019 10:52:25 +0100
Message-ID: <86ef3zgmg6.wl-marc.zyngier@arm.com>
From: Marc Zyngier <marc.zyngier@arm.com>
To: Julien Thierry <julien.thierry@arm.com>
Subject: Re: [PATCH v2 1/9] KVM: arm/arm64: vgic: Add LPI translation cache
 definition
In-Reply-To: <54c8547a-51fb-8ae5-975f-261d3934221a@arm.com>
References: <20190611170336.121706-1-marc.zyngier@arm.com>
 <20190611170336.121706-2-marc.zyngier@arm.com>
 <54c8547a-51fb-8ae5-975f-261d3934221a@arm.com>
User-Agent: Wanderlust/2.15.9 (Almost Unreal) SEMI-EPG/1.14.7 (Harue)
 FLIM/1.14.9 (=?UTF-8?B?R29qxY0=?=) APEL/10.8 EasyPG/1.0.0 Emacs/26
 (aarch64-unknown-linux-gnu) MULE/6.0 (HANACHIRUSATO)
Organization: ARM Ltd
MIME-Version: 1.0 (generated by SEMI-EPG 1.14.7 - "Harue")
Cc: kvm@vger.kernel.org, "Raslan,
 KarimAllah" <karahmed@amazon.de>, "Saidi, Ali" <alisaidi@amazon.com>,
 kvmarm@lists.cs.columbia.edu, linux-arm-kernel@lists.infradead.org
X-BeenThere: kvmarm@lists.cs.columbia.edu
X-Mailman-Version: 2.1.14
Precedence: list
List-Id: Where KVM/ARM decisions are made <kvmarm.lists.cs.columbia.edu>
List-Unsubscribe: <https://lists.cs.columbia.edu/mailman/options/kvmarm>,
 <mailto:kvmarm-request@lists.cs.columbia.edu?subject=unsubscribe>
List-Archive: <https://lists.cs.columbia.edu/pipermail/kvmarm>
List-Post: <mailto:kvmarm@lists.cs.columbia.edu>
List-Help: <mailto:kvmarm-request@lists.cs.columbia.edu?subject=help>
List-Subscribe: <https://lists.cs.columbia.edu/mailman/listinfo/kvmarm>,
 <mailto:kvmarm-request@lists.cs.columbia.edu?subject=subscribe>
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: 7bit
Errors-To: kvmarm-bounces@lists.cs.columbia.edu
Sender: kvmarm-bounces@lists.cs.columbia.edu

Hi Julien,

On Wed, 12 Jun 2019 09:16:21 +0100,
Julien Thierry <julien.thierry@arm.com> wrote:
> 
> Hi Marc,
> 
> On 11/06/2019 18:03, Marc Zyngier wrote:
> > Add the basic data structure that expresses an MSI to LPI
> > translation as well as the allocation/release hooks.
> > 
> > THe size of the cache is arbitrarily defined as 4*nr_vcpus.
> >
> 
> The size has been arbitrarily changed to 16*nr_vcpus :) .

Well spotted! ;-)

> 
> Nit: The*

Ah, usual lazy finger on the Shift key... One day I'll learn to type.

> 
> > Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
> > ---
> >  include/kvm/arm_vgic.h        |  3 +++
> >  virt/kvm/arm/vgic/vgic-init.c |  5 ++++
> >  virt/kvm/arm/vgic/vgic-its.c  | 49 +++++++++++++++++++++++++++++++++++
> >  virt/kvm/arm/vgic/vgic.h      |  2 ++
> >  4 files changed, 59 insertions(+)
> > 
> > diff --git a/include/kvm/arm_vgic.h b/include/kvm/arm_vgic.h
> > index c36c86f1ec9a..ca7bcf52dc85 100644
> > --- a/include/kvm/arm_vgic.h
> > +++ b/include/kvm/arm_vgic.h
> > @@ -260,6 +260,9 @@ struct vgic_dist {
> >  	struct list_head	lpi_list_head;
> >  	int			lpi_list_count;
> >  
> > +	/* LPI translation cache */
> > +	struct list_head	lpi_translation_cache;
> > +
> >  	/* used by vgic-debug */
> >  	struct vgic_state_iter *iter;
> >  
> > diff --git a/virt/kvm/arm/vgic/vgic-init.c b/virt/kvm/arm/vgic/vgic-init.c
> > index 3bdb31eaed64..c7c4c77dd430 100644
> > --- a/virt/kvm/arm/vgic/vgic-init.c
> > +++ b/virt/kvm/arm/vgic/vgic-init.c
> > @@ -64,6 +64,7 @@ void kvm_vgic_early_init(struct kvm *kvm)
> >  	struct vgic_dist *dist = &kvm->arch.vgic;
> >  
> >  	INIT_LIST_HEAD(&dist->lpi_list_head);
> > +	INIT_LIST_HEAD(&dist->lpi_translation_cache);
> >  	raw_spin_lock_init(&dist->lpi_list_lock);
> >  }
> >  
> > @@ -305,6 +306,7 @@ int vgic_init(struct kvm *kvm)
> >  	}
> >  
> >  	if (vgic_has_its(kvm)) {
> > +		vgic_lpi_translation_cache_init(kvm);
> >  		ret = vgic_v4_init(kvm);
> >  		if (ret)
> >  			goto out;
> > @@ -346,6 +348,9 @@ static void kvm_vgic_dist_destroy(struct kvm *kvm)
> >  		INIT_LIST_HEAD(&dist->rd_regions);
> >  	}
> >  
> > +	if (vgic_has_its(kvm))
> > +		vgic_lpi_translation_cache_destroy(kvm);
> > +
> >  	if (vgic_supports_direct_msis(kvm))
> >  		vgic_v4_teardown(kvm);
> >  }
> > diff --git a/virt/kvm/arm/vgic/vgic-its.c b/virt/kvm/arm/vgic/vgic-its.c
> > index 44ceaccb18cf..ce9bcddeb7f1 100644
> > --- a/virt/kvm/arm/vgic/vgic-its.c
> > +++ b/virt/kvm/arm/vgic/vgic-its.c
> > @@ -149,6 +149,14 @@ struct its_ite {
> >  	u32 event_id;
> >  };
> >  
> > +struct vgic_translation_cache_entry {
> > +	struct list_head	entry;
> > +	phys_addr_t		db;
> > +	u32			devid;
> > +	u32			eventid;
> > +	struct vgic_irq		*irq;
> > +};
> > +
> >  /**
> >   * struct vgic_its_abi - ITS abi ops and settings
> >   * @cte_esz: collection table entry size
> > @@ -1668,6 +1676,45 @@ static int vgic_register_its_iodev(struct kvm *kvm, struct vgic_its *its,
> >  	return ret;
> >  }
> >  
> > +/* Default is 16 cached LPIs per vcpu */
> > +#define LPI_DEFAULT_PCPU_CACHE_SIZE	16
> > +
> > +void vgic_lpi_translation_cache_init(struct kvm *kvm)
> > +{
> > +	struct vgic_dist *dist = &kvm->arch.vgic;
> > +	unsigned int sz;
> > +	int i;
> > +
> > +	if (!list_empty(&dist->lpi_translation_cache))
> > +		return;
> > +
> > +	sz = atomic_read(&kvm->online_vcpus) * LPI_DEFAULT_PCPU_CACHE_SIZE;
> > +
> > +	for (i = 0; i < sz; i++) {
> > +		struct vgic_translation_cache_entry *cte;
> > +
> > +		/* An allocation failure is not fatal */
> > +		cte = kzalloc(sizeof(*cte), GFP_KERNEL);
> > +		if (WARN_ON(!cte))
> > +			break;
> > +
> > +		INIT_LIST_HEAD(&cte->entry);
> > +		list_add(&cte->entry, &dist->lpi_translation_cache);
> 
> Going through the series, it looks like this list is either empty
> (before the cache init) or has a fixed number
> (LPI_DEFAULT_PCPU_CACHE_SIZE * nr_cpus) of entries.

Well, it could also fail when allocating one of the entry, meaning we
can have an allocation ranging from 0 to (LPI_DEFAULT_PCPU_CACHE_SIZE
* nr_cpus) entries.

> And the list never grows nor shrinks throughout the series, so it
> seems odd to be using a list here.
> 
> Is there a reason for not using a dynamically allocated array instead of
> the list? (does list_move() provide a big perf advantage over swapping
> the data from one array entry to another? Or is there some other
> facility I am missing?

The idea was to make the LRU policy cheap, on the assumption that
list_move (which is only a couple of pointer updates) is cheaper than
a memmove if you want to keep the array ordered. If we exclude the
list head, we end-up with 24 bytes per entry to move down to make room
for the new entry at the head of the array. For large caches that miss
very often, this will hurt badly. But is that really a problem? I
don't know.

We could allocate an array as you suggest, and use a linked list
inside the array. Or something else. I'm definitely open to
suggestion!

Thanks,

	M.

-- 
Jazz is not dead, it just smells funny.
_______________________________________________
kvmarm mailing list
kvmarm@lists.cs.columbia.edu
https://lists.cs.columbia.edu/mailman/listinfo/kvmarm
